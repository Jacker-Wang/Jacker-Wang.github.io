---
layout: "post"
title: "Hadoop分布式集群搭建"
date: "2017-08-17 10:23"
catalog: true
---



# 基础环境

----------

## 环境准备
----

 1，软件版本

 （1）在VMWare上面跑了三台虚拟机：CentOS7，系统内核3.10

 （2）三台虚拟机的IP：192.168.102.3，192.168.102.4，192.168.102.5。三台机器分别作为hadoop的master，slaveA，slaveB。

 （3）jdk1.8。

 （4）hadoop2.7.3.download：http://apache.claz.org/hadoop/common/hadoop-2.7.3/hadoop-2.7.3.tar.gz

 2，hostname设置
 设置每台主机的hostname，这个文件位置随着系统的不同而不同，下面是CentOS7的hostname文件位置。
```
#vim /etc/hostname
```
文件中添加
```
Master
```
相应的其它两台机器设置此文件中的内容为SlaveA，SlaveB，重启有效，在下一步重启。

 3， hosts配置（ip-hostname映射）

```
vim /etc/hosts
```
```
 192.168.102.3  Master
 192.168.102.4  SlaveA
 192.168.102.5  SlaveB
```

三台机器都需要做相同的设置，然后重启三台机器，让文件修改生效。


## SSH免密登录
-------

一，关闭防火墙和SELINUX
配置ssh免密登录首先需要关闭防火墙和SELINUX。
1，我这里在本机CentOS7中进行了永久的防火墙关闭
关闭防火墙（其它的发行版关闭防火墙的命令是不同的）
```
//永久关闭防火墙
#chkconfig firewalld off
//查看防火墙状态
#systemctl status firewalld
```
关闭SELINUX

```
vim /etc/SELINUX/config
//注释掉所有，然后添加下面一行
SELINUX=disabled
```
以上两个步骤在三台机器中都要进行配置和设置。

二，配置ssh的免密登录

```
#cd ~/.ssh
#ssh-keygen -t rsa
//生成密钥的过程连续输入回车即可。
```
上述命令完成后~/.ssh目录中会多出id_rsa和id_rsa.pub文件。

1，配置master可以免密登录本机master

```
//将id_rsa.pub的文件内容追加到文件authorized_keys中
#cd ~/.ssh
#cat id_rsa.pub>>authorized_keys
```
这个时候使用以下命令登录主机master应该是不用输入密码可以直接登录的。

```
ssh master
```

2，配置master可以免密登录slaveA

```
//将master的id_rsa.pub拷贝到slaveA
#scp ~/.ssh/id_rsa.pub root@slaveA:/root/
//登录到slaveA，将拷贝过来的id_rsa.pub内容追加到~/.ssh/authorized_keys
#cd ~
#cat id_rsa.pub>>.ssh/authorized_keys
```
这个回到主机master进行登录主机slavaA是不用输入密码的。

```
ssh slaveA
```
3，配置master可以免密登录slaveB
这个过程和第二步中免密登录slaveA是同样的操作。

# Hadoop集群搭建
----------

## master环境搭建
1，下载hadoop2.7.3，然后进行解压
2，将hadoop系列命令加入PATH路径
```
#vim /etc/profile
//HADOOP_HOME变量的值换成自己的路径
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin
```
3，配置core-site.xml

```
#vim $HADOOP_HOME/etc/hadoop/core-site.xml
//添加如下内容
<configuration>
     <!--
    指定hadoop临时目录，否则默认是在/tmp下面，这个目录每次系
    统重启后会删除，所以每次启动hadoop都要执行namenode格式化。
    这里的目录需要自己创建。
      -->
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/usr/local/hadoop/tmp</value>
        <description>Abase for other temporary
         directories.</description>
    </property>
    <!--设定namenode的ip/host和port,这里host换成你自己的
      hostname
    -->
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>
</configuration>
```
4，配置hdfs-site.xml

```
#vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml

//添加如下内容
<configuration>
    //设定数据的复制份数，因为我这里有两台slave，所以设置为2
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    //设置namenode节点的数据存储目录，这个目录需要自己创建
    <property>
        <name>dfs.name.dir</name>
        <value>/usr/local/hadoop/hdfs/name</value>
    </property>
    //设置datanode节点的数据存储目录，这个目录需要自己创建
    <property>
        <name>dfs.data.dir</name>
        <value>/usr/local/hadoop/hdfs/data</value>
    </property>
</configuration>
```

5，配置mapred-site.xml

```
#cd $HADOOP_HOME/etc/hadoop
#cp mapred-site.xml.default mapred-site.xml
#vim mapred-site.xml
//添加以下内容
<configuration>
  <property>
      <name>mapreduce.framework.name</name>
      <value>yarn</value>
  </property>
   <property>
      <name>mapred.job.tracker</name>
      <value>http://master:9001</value>
  </property>
</configuration>
```
6，配置yarn-site.xml

```
<configuration>
<!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    //指定resourceManager节点
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
    </property>
</configuration>
```
7，配置slavas文件

```
#cd $HADOOP_HOME/etc/hadoop
#vim slaves
//添加两台slave
slaveA
slaveB
```

## slaves环境搭建

这里配置slave的环境将master中配置好的hadoop目录中多有文件复制过来即可，包括复制hadoop目录和自己创建的数据目录，这里使用scp命令进行远程复制。
1，复制hadoop目录

```
#scp $HADOOP_HOME root@slaveA:$HADOOP_HOME/..
#scp $HADOOP_HOME root@slaveB:$HADOOP_HOME/..
```
2，复制data目录
同样使用scp命令将master中创建的data目录和tmp目录复制到两个slave中。
至此hadoop集群搭建完成，下面进行测试。

# 启动Hadoop

----------
1，第一次启动需要进行格式化。

```
#hdfs namenode -format
```
2，启动hadoop集群，下面命令在master中进行

```
#start-all.sh
```
使用jsp命令查看在各个机器中的进程，如果显示以下进程则说明配置正确。

```
#jsp
```
master中进程
>NameNode
>
>SecondaryNameNode
>
>ResourceManager

slave中进程
>DataNode

>NodeManager
